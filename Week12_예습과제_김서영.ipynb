{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ccd9a8",
      "metadata": {
        "id": "07ccd9a8",
        "outputId": "afe5567d-5b7c-416b-842d-d79449686558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.2.1+cpu\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: d:\\anaconda\\Lib\\site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
            "Required-by: torchaudio, torchdata, torchtext, torchvision\n",
            "---\n",
            "Name: matplotlib\n",
            "Version: 3.9.2\n",
            "Summary: Python plotting package\n",
            "Home-page: https://matplotlib.org\n",
            "Author: John D. Hunter, Michael Droettboom\n",
            "Author-email: Unknown <matplotlib-users@python.org>\n",
            "License: License agreement for matplotlib versions 1.3.0 and later\n",
            "=========================================================\n",
            "\n",
            "1. This LICENSE AGREEMENT is between the Matplotlib Development Team\n",
            "(\"MDT\"), and the Individual or Organization (\"Licensee\") accessing and\n",
            "otherwise using matplotlib software in source or binary form and its\n",
            "associated documentation.\n",
            "\n",
            "2. Subject to the terms and conditions of this License Agreement, MDT\n",
            "hereby grants Licensee a nonexclusive, royalty-free, world-wide license\n",
            "to reproduce, analyze, test, perform and/or display publicly, prepare\n",
            "derivative works, distribute, and otherwise use matplotlib\n",
            "alone or in any derivative version, provided, however, that MDT's\n",
            "License Agreement and MDT's notice of copyright, i.e., \"Copyright (c)\n",
            "2012- Matplotlib Development Team; All Rights Reserved\" are retained in\n",
            "matplotlib  alone or in any derivative version prepared by\n",
            "Licensee.\n",
            "\n",
            "3. In the event Licensee prepares a derivative work that is based on or\n",
            "incorporates matplotlib or any part thereof, and wants to\n",
            "make the derivative work available to others as provided herein, then\n",
            "Licensee hereby agrees to include in any such work a brief summary of\n",
            "the changes made to matplotlib .\n",
            "\n",
            "4. MDT is making matplotlib available to Licensee on an \"AS\n",
            "IS\" basis.  MDT MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n",
            "IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, MDT MAKES NO AND\n",
            "DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n",
            "FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB\n",
            "WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n",
            "\n",
            "5. MDT SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB\n",
            " FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR\n",
            "LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING\n",
            "MATPLOTLIB , OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF\n",
            "THE POSSIBILITY THEREOF.\n",
            "\n",
            "6. This License Agreement will automatically terminate upon a material\n",
            "breach of its terms and conditions.\n",
            "\n",
            "7. Nothing in this License Agreement shall be deemed to create any\n",
            "relationship of agency, partnership, or joint venture between MDT and\n",
            "Licensee.  This License Agreement does not grant permission to use MDT\n",
            "trademarks or trade name in a trademark sense to endorse or promote\n",
            "products or services of Licensee, or any third party.\n",
            "\n",
            "8. By copying, installing or otherwise using matplotlib ,\n",
            "Licensee agrees to be bound by the terms and conditions of this License\n",
            "Agreement.\n",
            "\n",
            "License agreement for matplotlib versions prior to 1.3.0\n",
            "========================================================\n",
            "\n",
            "1. This LICENSE AGREEMENT is between John D. Hunter (\"JDH\"), and the\n",
            "Individual or Organization (\"Licensee\") accessing and otherwise using\n",
            "matplotlib software in source or binary form and its associated\n",
            "documentation.\n",
            "\n",
            "2. Subject to the terms and conditions of this License Agreement, JDH\n",
            "hereby grants Licensee a nonexclusive, royalty-free, world-wide license\n",
            "to reproduce, analyze, test, perform and/or display publicly, prepare\n",
            "derivative works, distribute, and otherwise use matplotlib\n",
            "alone or in any derivative version, provided, however, that JDH's\n",
            "License Agreement and JDH's notice of copyright, i.e., \"Copyright (c)\n",
            "2002-2011 John D. Hunter; All Rights Reserved\" are retained in\n",
            "matplotlib  alone or in any derivative version prepared by\n",
            "Licensee.\n",
            "\n",
            "3. In the event Licensee prepares a derivative work that is based on or\n",
            "incorporates matplotlib  or any part thereof, and wants to\n",
            "make the derivative work available to others as provided herein, then\n",
            "Licensee hereby agrees to include in any such work a brief summary of\n",
            "the changes made to matplotlib.\n",
            "\n",
            "4. JDH is making matplotlib  available to Licensee on an \"AS\n",
            "IS\" basis.  JDH MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n",
            "IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, JDH MAKES NO AND\n",
            "DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n",
            "FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB\n",
            "WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n",
            "\n",
            "5. JDH SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB\n",
            " FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR\n",
            "LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING\n",
            "MATPLOTLIB , OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF\n",
            "THE POSSIBILITY THEREOF.\n",
            "\n",
            "6. This License Agreement will automatically terminate upon a material\n",
            "breach of its terms and conditions.\n",
            "\n",
            "7. Nothing in this License Agreement shall be deemed to create any\n",
            "relationship of agency, partnership, or joint venture between JDH and\n",
            "Licensee.  This License Agreement does not grant permission to use JDH\n",
            "trademarks or trade name in a trademark sense to endorse or promote\n",
            "products or services of Licensee, or any third party.\n",
            "\n",
            "8. By copying, installing or otherwise using matplotlib,\n",
            "Licensee agrees to be bound by the terms and conditions of this License\n",
            "Agreement.\n",
            "Location: d:\\anaconda\\Lib\\site-packages\n",
            "Requires: contourpy, cycler, fonttools, kiwisolver, numpy, packaging, pillow, pyparsing, python-dateutil\n",
            "Required-by: catboost, seaborn\n",
            "---\n",
            "Name: numpy\n",
            "Version: 1.26.4\n",
            "Summary: Fundamental package for array computing in Python\n",
            "Home-page: https://numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: Copyright (c) 2005-2023, NumPy Developers.\n",
            "All rights reserved.\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without\n",
            "modification, are permitted provided that the following conditions are\n",
            "met:\n",
            "\n",
            "    * Redistributions of source code must retain the above copyright\n",
            "       notice, this list of conditions and the following disclaimer.\n",
            "\n",
            "    * Redistributions in binary form must reproduce the above\n",
            "       copyright notice, this list of conditions and the following\n",
            "       disclaimer in the documentation and/or other materials provided\n",
            "       with the distribution.\n",
            "\n",
            "    * Neither the name of the NumPy Developers nor the names of any\n",
            "       contributors may be used to endorse or promote products derived\n",
            "       from this software without specific prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n",
            "\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n",
            "LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n",
            "A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n",
            "OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
            "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n",
            "LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n",
            "DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n",
            "THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
            "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
            "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
            "Location: d:\\anaconda\\Lib\\site-packages\n",
            "Requires: \n",
            "Required-by: altair, astropy, bokeh, Bottleneck, catboost, contourpy, datasets, datashader, gensim, h5py, holoviews, hvplot, imagecodecs, imageio, imbalanced-learn, lightgbm, matplotlib, mkl_fft, mkl_random, numba, numexpr, opencv-python, opencv-python-headless, optuna, pandas, patsy, pyarrow, pydeck, pyerfa, PyWavelets, sacrebleu, scikit-image, scikit-learn, scipy, seaborn, statsmodels, streamlit, tables, tifffile, torchtext, torchvision, transformers, xarray, xgboost\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show torch matplotlib numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9933e313",
      "metadata": {
        "id": "9933e313"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91f90b05",
      "metadata": {
        "id": "91f90b05",
        "outputId": "6cff4d20-b1ba-4cc3-a109-8e829fc7ed91"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#  \n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class PositionalEncoding(nn.Module): # :  (d_model),  (max_len)\n",
        "    def __init__(self, d_model, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "#  \n",
        "encoding = PositionalEncoding(d_model=128, max_len=50)\n",
        "plt.pcolormesh(encoding.pe.detach().numpy().squeeze(), cmap=\"RdBu\")\n",
        "plt.xlabel(\"Embedding Dimension\")\n",
        "plt.xlim((0, 128))\n",
        "plt.ylabel(\"Position\")\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f860b43",
      "metadata": {
        "id": "2f860b43",
        "outputId": "ecdc7883-a21c-4647-a9a4-843b92ec1efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in d:\\anaconda\\lib\\site-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\anaconda\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\anaconda\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda\\lib\\site-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in d:\\anaconda\\lib\\site-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\anaconda\\lib\\site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\anaconda\\lib\\site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\anaconda\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\anaconda\\lib\\site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\anaconda\\lib\\site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda\\lib\\site-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.0 in d:\\anaconda\\lib\\site-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda\\lib\\site-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\anaconda\\lib\\site-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\anaconda\\lib\\site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in d:\\anaconda\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in d:\\anaconda\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\anaconda\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Collecting numpy>=1.19.0 (from spacy)\n",
            "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\anaconda\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "Successfully installed numpy-2.2.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3f4c59",
      "metadata": {
        "id": "bd3f4c59",
        "outputId": "df2073da-a332-4bc3-a343-d0fdbaaa8ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 2.2.6\n",
            "Uninstalling numpy-2.2.6:\n",
            "  Successfully uninstalled numpy-2.2.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Failed to remove contents in a temporary directory 'D:\\anaconda\\Lib\\site-packages\\~umpy.libs'.\n",
            "You can safely remove it manually.\n",
            "WARNING: Failed to remove contents in a temporary directory 'D:\\anaconda\\Lib\\site-packages\\~-mpy'.\n",
            "You can safely remove it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a15da5",
      "metadata": {
        "id": "f4a15da5",
        "outputId": "fb3c9272-04cd-48f0-8261-4467e881e928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "     ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 1.0/14.6 MB 6.3 MB/s eta 0:00:03\n",
            "     ------ --------------------------------- 2.4/14.6 MB 6.1 MB/s eta 0:00:03\n",
            "     ---------- ----------------------------- 3.7/14.6 MB 5.9 MB/s eta 0:00:02\n",
            "     ------------- -------------------------- 5.0/14.6 MB 6.0 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 6.0/14.6 MB 5.8 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 7.3/14.6 MB 5.9 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 8.7/14.6 MB 5.8 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 10.0/14.6 MB 5.9 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 11.3/14.6 MB 5.9 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 12.3/14.6 MB 5.9 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 13.6/14.6 MB 5.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 14.6/14.6 MB 5.8 MB/s eta 0:00:00\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     --- ------------------------------------ 1.0/12.8 MB 5.6 MB/s eta 0:00:03\n",
            "     ------- -------------------------------- 2.4/12.8 MB 5.8 MB/s eta 0:00:02\n",
            "     ----------- ---------------------------- 3.7/12.8 MB 5.9 MB/s eta 0:00:02\n",
            "     --------------- ------------------------ 5.0/12.8 MB 5.9 MB/s eta 0:00:02\n",
            "     ------------------- -------------------- 6.3/12.8 MB 6.0 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 7.6/12.8 MB 5.9 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 8.9/12.8 MB 6.0 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 10.2/12.8 MB 6.0 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.5/12.8 MB 6.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.6/12.8 MB 6.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.8/12.8 MB 5.9 MB/s eta 0:00:00\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399c51f1",
      "metadata": {
        "id": "399c51f1",
        "outputId": "ff339a19-8119-4d11-8a83-cec231b008bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token Transform:\n",
            "{'de': functools.partial(<function _spacy_tokenize at 0x000001B00F831580>, spacy=<spacy.lang.de.German object at 0x000001B04A01C920>), 'en': functools.partial(<function _spacy_tokenize at 0x000001B00F831580>, spacy=<spacy.lang.en.English object at 0x000001B049FE4D10>)}\n",
            "Vocab Transform:\n",
            "{'de': Vocab(), 'en': Vocab()}\n"
          ]
        }
      ],
      "source": [
        "#    \n",
        "\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "def generate_tokens(text_iter, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for text in text_iter:\n",
        "        yield token_transform[language](text[language_index[language]])\n",
        "\n",
        "SRC_LANGUAGE = \"de\"\n",
        "TGT_LANGUAGE = \"en\"\n",
        "\n",
        "BOS_IDX = vocab_transform[TGT_LANGUAGE][\"<bos>\"]\n",
        "EOS_IDX = vocab_transform[TGT_LANGUAGE][\"<eos>\"]\n",
        "PAD_IDX = vocab_transform[TGT_LANGUAGE][\"<pad>\"]\n",
        "UNK_IDX = vocab_transform[TGT_LANGUAGE][\"<unk>\"]\n",
        "\n",
        "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "token_transform = {\n",
        "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n",
        "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
        "}\n",
        "\n",
        "print(\"Token Transform:\")\n",
        "print(token_transform)\n",
        "\n",
        "vocab_transform = {}\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    vocab_transform[language] = build_vocab_from_iterator(\n",
        "        generate_tokens(train_iter, language),\n",
        "        min_freq=1,\n",
        "        specials=special_symbols,\n",
        "        special_first=True,\n",
        "    )\n",
        "\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[language].set_default_index(UNK_IDX)\n",
        "\n",
        "print(\"Vocab Transform:\")\n",
        "print(vocab_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d683b2a9",
      "metadata": {
        "id": "d683b2a9"
      },
      "outputs": [],
      "source": [
        "#   \n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        emb_size,\n",
        "        max_len,\n",
        "        nhead,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        dim_feedforward,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            d_model=emb_size, max_len=max_len, dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=emb_size,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        src,\n",
        "        trg,\n",
        "        src_mask,\n",
        "        tgt_mask,\n",
        "        src_padding_mask,\n",
        "        tgt_padding_mask,\n",
        "        memory_key_padding_mask,\n",
        "    ):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(\n",
        "            src=src_emb,\n",
        "            tgt=tgt_emb,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            memory_mask=None,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=memory_key_padding_mask,\n",
        "        )\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.transformer.encoder(\n",
        "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
        "        )\n",
        "\n",
        "    def decode(self, tgt, memory, tgt_mask):\n",
        "        return self.transformer.decoder(\n",
        "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1574c511",
      "metadata": {
        "id": "1574c511",
        "outputId": "d5a4c701-a7d9-43c3-9ebe-db5729507925"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src_tok_emb\n",
            "|   embedding\n",
            "tgt_tok_emb\n",
            "|   embedding\n",
            "positional_encoding\n",
            "|   dropout\n",
            "transformer\n",
            "|   encoder\n",
            "|  |   layers\n",
            "|  |  |   0\n",
            "|  |  |   1\n",
            "|  |  |   2\n",
            "|  |   norm\n",
            "|   decoder\n",
            "|  |   layers\n",
            "|  |  |   0\n",
            "|  |  |   1\n",
            "|  |  |   2\n",
            "|  |   norm\n",
            "generator\n"
          ]
        }
      ],
      "source": [
        "#   \n",
        "\n",
        "from torch import optim\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = Seq2SeqTransformer(\n",
        "    num_encoder_layers=3,\n",
        "    num_decoder_layers=3,\n",
        "    emb_size=512,\n",
        "    max_len=512,\n",
        "    nhead=8,\n",
        "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
        "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
        "    dim_feedforward=512,\n",
        ").to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"|  \", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"|  |  \", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"|  |  |  \", sssub_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dac554",
      "metadata": {
        "id": "f5dac554",
        "outputId": "d8268f9e-e59c-40d4-9842-64ebf967d217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(source, target):\n",
            "('Eine Gruppe von Mnnern ldt Baumwolle auf einen Lastwagen', 'A group of men are loading cotton onto a truck')\n",
            "source_batch: torch.Size([30, 32])\n",
            "tensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2],\n",
            "        [   14,     5,     5,    21,     5,    14,     5,     5,     5,    14,\n",
            "             5,    14,    60,    14,    14,    60,     5,    14,    14,    60,\n",
            "             5,    17,     5,     5,   303,    21,     5,    60,    14,     5,\n",
            "             5,    14],\n",
            "        [   38,    12,    35,    31,    12,    17,   175,    75,    12,   755,\n",
            "            69,    68,   114,    17,    17,    54,     0,    38,    85,    27,\n",
            "          1268,     9,    12,   706,    53,   123,  7835,    31,    68,  1428,\n",
            "           180,    68],\n",
            "        [   24,   281,    10,   957,    10,     7,    33,    35,   342,    17,\n",
            "            50,    11,    67,    32,    40,    11,    12,    24,    17,     8,\n",
            "            12,    12,    10,    27,    11,    59,   164,    77,   113,  1096,\n",
            "            27,   551],\n",
            "        [  243,     7,  1205,    18,  7190,     6,   127,    10,     7,    10,\n",
            "            30,     6,    53,    63,    15,    74,   281,    54,  3489,    24,\n",
            "             7,    77,     6,    10,    13,    22,   172,    11,  2915,   712,\n",
            "            86,    19],\n",
            "        [ 2744,     6,    32,   420,  2328,   238,    26,     6,     6,     6,\n",
            "          1006, 13620,    66,   177,  1412, 10377,   140,    30,    22,   360,\n",
            "             6,    43,   455,   390,   564,   392,     6,    13,    43,    91,\n",
            "          1006,    36],\n",
            "        [ 8680,    83,    11,     0,     8,   213,    72,     0,  3138,  7693,\n",
            "            11,   338,    15,     0,    11,     9,    11,    28,     0,    45,\n",
            "            72, 17401,   878,   108,     3,   120,    99,    36,     6,    34,\n",
            "            58,     9],\n",
            "        [   11,   245,    34,    11,    16,     8,    33,   620,  1021,  6950,\n",
            "             6,    22,  7247,    11,   306,     6,    79,    13,  4929,   345,\n",
            "           122,  3265,     9,     9,     1,    10,    50,     7,    80,  1823,\n",
            "            20,     0],\n",
            "        [   20,    11,   792,     6,    18,    19,  1072,    20,     3,    39,\n",
            "         19011,   404,  2120,     6,   842,  2929,   272,     0,    23,   332,\n",
            "             0,    10,   879,   490,     1,     6,    29,    34,   354,    13,\n",
            "           155,   150],\n",
            "        [  892,     6,    13,     0,   362,    18,     4,  1947,     1,    15,\n",
            "           216,     4,   144,  3747,     4,   141,     4,    11,     3,     8,\n",
            "            19, 15197,   150,  1929,     1,   465,     4,   638,     4, 14510,\n",
            "             4,    19],\n",
            "        [    3,   444,    17,   318,  3914,  3599,     3,     7,     1,  1299,\n",
            "             4,     3,     4,     4,     3,    58,     3,     6,     1,    53,\n",
            "            99,  1373,    10,  1046,     1,   320,     3,     4,     3,     4,\n",
            "             3,     0],\n",
            "        [    1,     4,     4,    11,    62,    55,     1,   381,     1,     3,\n",
            "             3,     1,     3,     3,     1,  1126,     1,   628,     1,     7,\n",
            "            54,     4, 12196,    11,     1,     4,     1,     3,     1,     3,\n",
            "             1,  1110],\n",
            "        [    1,     3,     3,     3,     8,  1626,     1,    45,     1,     1,\n",
            "             1,     1,     1,     1,     1,   120,     1,     4,     1,    13,\n",
            "             7,     3,     4,     6,     1,     3,     1,     1,     1,     1,\n",
            "             1,     4],\n",
            "        [    1,     1,     1,     1,    32,     0,     1,  5063,     1,     1,\n",
            "             1,     1,     1,     1,     1,     4,     1,     3,     1,   343,\n",
            "            13,     1,     3,  1876,     1,     1,     1,     1,     1,     1,\n",
            "             1,     3],\n",
            "        [    1,     1,     1,     1,     7,   932,     1,  1238,     1,     1,\n",
            "             1,     1,     1,     1,     1,     3,     1,     1,     1,    36,\n",
            "           723,     1,     1,     4,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     6,     7,     1,     4,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     9,\n",
            "          4097,     1,     1,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,   115,     6,     1,     3,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,   982,\n",
            "           569,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,   197,    47,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,  1559,\n",
            "             4,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     4,  9883,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     4,\n",
            "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     3,    39,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     3,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     8,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    71,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    91,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    20,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,  4826,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     7,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    19,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    95,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     4,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     3,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]])\n",
            "target_batch: torch.Size([27, 32])\n",
            "tensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2],\n",
            "        [    6,     6,     6,    19,     6,     6,     6,     6,     6,     6,\n",
            "             6,     6,    59,     6,     6,    59,     6,     6,     6,    59,\n",
            "             6,   275,     6,    53,   736,    19,     6,    59,     6,     6,\n",
            "             6,     6],\n",
            "        [   39,    12,    35,    36,  1489,   128,    65,    25,    12,   136,\n",
            "            25,    72,    25,    16,   193,    22,  1347,    39,    25,   110,\n",
            "          2111,    11,    12,   141,   266,   117,  2043,    36,    72,  1121,\n",
            "            25,    72],\n",
            "        [   13,   383,    21,   412,    12,     7,    34,    35,     7,    16,\n",
            "            58,     9,    73,    10,    38,     9,  1526,    13,    16,   513,\n",
            "            12,    12,     7,    33,    37,   127,   157,    17,    10,    10,\n",
            "            33,  1563],\n",
            "        [   36,     7,   759,    50,    21,     4,    10,    21,     4,     7,\n",
            "            10,     4,   104,    32,     4,    66,    12,    22,    10,   741,\n",
            "             7,    42,     4,     7,     9,    14,    10,    42,  2232,   891,\n",
            "            82,     8],\n",
            "        [   17,     4,    96,     4,     4,    31,    82,     4,  2334,     4,\n",
            "            37,  5964,    87,    48,  1414,   179,    10,    37,   298,    60,\n",
            "             4,   174,   466,     4,   113,    28,   136,     9,    79,   179,\n",
            "            48,    40],\n",
            "        [ 1667,    51,     9,    30,    31,   197,   390,  6675,   772,  3692,\n",
            "           737,     7,     4,    45,     9,    43,   383,     7,  2919,    54,\n",
            "            26,   253,    10,    51,    13,    91,    20,     4,     4,    18,\n",
            "          1349,    11],\n",
            "        [ 2541,   189,     4,   272,   748,    15,     8,   503,    10,   321,\n",
            "             9,  1145,    30,  4188,    45,   463,     9,    44,     7,   302,\n",
            "           226,   395,    97,    68,     4,   227,    86,   147,    62,   953,\n",
            "             7,     0],\n",
            "        [  342,     9,    16,   382,    85,    46,    26,   777,   199,   113,\n",
            "            88,   277,    11,   542,   713,    11,    27,    13,     8,     4,\n",
            "            43,   367,    29,    11,   322,     7,    58,     7,   311,  3460,\n",
            "             4,     8],\n",
            "        [    4,     4,   106,  1923,    10,     4,    34,     4,     8,    94,\n",
            "          5534,     5,    24,   622,     5,    54,   247,     4,   569,   425,\n",
            "            23,    14,  1106,   508,    13,   422,     5,     8,    13,    50,\n",
            "           120, 10269],\n",
            "        [  282,   439,   893,     9,    32,  7769,     5,   195,  1768,    46,\n",
            "           411,     3,  1491,    20,     3,   413,   354,  1923,   409,    29,\n",
            "            37,     4,  4340,    10,  1302,   101,     3,   498,    47,     4,\n",
            "             5,    13],\n",
            "        [    3,     5,     5,    28,     7,   142,     3,   867,     3,     4,\n",
            "             5,     1,     5,    28,     1,    43,     5,     7,     3,   257,\n",
            "           329,  3477,     5,  1198,     5,     5,     1,     5,     5,  9909,\n",
            "             3,   567],\n",
            "        [    1,     3,     3,  5504,     4,   269,     1,    20,     1,   225,\n",
            "             3,     1,     3,    57,     1,  2288,     3,     4,     1,   104,\n",
            "             8,   207,     3,   616,     3,     3,     1,     3,     3,   114,\n",
            "             1,     5],\n",
            "        [    1,     1,     1,    79,    77,  3633,     1,    28,     1,   105,\n",
            "             1,     1,     1,   292,     1,    17,     1,   592,     1,     7,\n",
            "            93,   352,     1,     9,     1,     1,     1,     1,     1,     5,\n",
            "             1,     3],\n",
            "        [    1,     1,     1,   325,   184,    13,     1,  3609,     1,     3,\n",
            "             1,     1,     1,     5,     1,    81,     1,   392,     1,     4,\n",
            "            20,   149,     1,     4,     1,     1,     1,     1,     1,     3,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     3,     5,   401,     1,  1533,     1,     1,\n",
            "             1,     1,     1,     3,     1,    63,     1,     5,     1,   270,\n",
            "             4,     5,     1,  1990,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     3,  1904,     1,     5,     1,     1,\n",
            "             1,     1,     1,     1,     1,    65,     1,     3,     1,    40,\n",
            "           270,     3,     1,     5,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    15,     1,     3,     1,     1,\n",
            "             1,     1,     1,     1,     1,   101,     1,     1,     1,     5,\n",
            "           385,     1,     1,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    97,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     5,     1,     1,     1,     3,\n",
            "             5,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,   115,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     3,     1,     1,     1,     1,\n",
            "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     8,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,   187,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,    55,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     4,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     0,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     5,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    1,     1,     1,     1,     1,     3,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "#   \n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "def input_transform(token_ids):\n",
        "    return torch.cat(\n",
        "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n",
        "    )\n",
        "\n",
        "def collator(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "text_transform = {}\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[language] = sequential_transforms(\n",
        "        token_transform[language], vocab_transform[language], input_transform\n",
        "    )\n",
        "\n",
        "data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator,num_workers=0)\n",
        "source_tensor, target_tensor = next(iter(dataloader))\n",
        "\n",
        "print(\"(source, target):\")\n",
        "print(next(iter(data_iter)))\n",
        "\n",
        "print(\"source_batch:\", source_tensor.shape)\n",
        "print(source_tensor)\n",
        "\n",
        "print(\"target_batch:\", target_tensor.shape)\n",
        "print(target_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e345616",
      "metadata": {
        "id": "7e345616",
        "outputId": "113014d1-f5a0-4807-94e2-c5bfa2365299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source_mask: torch.Size([30, 30])\n",
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False]])\n",
            "target_mask: torch.Size([26, 26])\n",
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0.]])\n",
            "source_padding_mask: torch.Size([32, 30])\n",
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n",
            "target_padding_mask: torch.Size([32, 26])\n",
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True]])\n"
          ]
        }
      ],
      "source": [
        "#   \n",
        "\n",
        "def generate_square_subsequent_mask(s):\n",
        "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = (\n",
        "        mask.float()\n",
        "        .masked_fill(mask == 0, float(\"-inf\"))\n",
        "        .masked_fill(mask == 1, float(0.0))\n",
        "    )\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "target_input = target_tensor[:-1, :]\n",
        "target_out = target_tensor[1:, :]\n",
        "\n",
        "source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n",
        "    source_tensor, target_input\n",
        ")\n",
        "\n",
        "print(\"source_mask:\", source_mask.shape)\n",
        "print(source_mask)\n",
        "\n",
        "print(\"target_mask:\", target_mask.shape)\n",
        "print(target_mask)\n",
        "\n",
        "print(\"source_padding_mask:\", source_padding_mask.shape)\n",
        "print(source_padding_mask)\n",
        "\n",
        "print(\"target_padding_mask:\", target_padding_mask.shape)\n",
        "print(target_padding_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b898e8e6",
      "metadata": {
        "id": "b898e8e6",
        "outputId": "12a59934-8a87-45e0-d550-ba295276c8ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train loss: 5.261, Val loss: 5.085\n",
            "Epoch: 2, Train loss: 5.431, Val loss: 5.700\n",
            "Epoch: 3, Train loss: 5.388, Val loss: 7.551\n",
            "Epoch: 4, Train loss: 5.288, Val loss: 8.662\n",
            "Epoch: 5, Train loss: 5.226, Val loss: 8.874\n"
          ]
        }
      ],
      "source": [
        "#    \n",
        "\n",
        "def run(model, optimizer, criterion, split):\n",
        "    model.train() if split == \"train\" else model.eval()\n",
        "    data_iter = Multi30k(split=split, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
        "\n",
        "    losses = 0\n",
        "    for source_batch, target_batch in dataloader:\n",
        "        source_batch = source_batch.to(DEVICE)\n",
        "        target_batch = target_batch.to(DEVICE)\n",
        "\n",
        "        target_input = target_batch[:-1, :]\n",
        "        target_output = target_batch[1:, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
        "            source_batch, target_input\n",
        "        )\n",
        "\n",
        "        logits = model(\n",
        "            src=source_batch,\n",
        "            trg=target_input,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_padding_mask=src_padding_mask,\n",
        "            tgt_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=src_padding_mask,\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1))\n",
        "        if split == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(dataloader))\n",
        "\n",
        "for epoch in range(5):\n",
        "    train_loss = run(model, optimizer, criterion, \"train\")\n",
        "    val_loss = run(model, optimizer, criterion, \"valid\")\n",
        "    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d26639",
      "metadata": {
        "id": "23d26639"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
        "    source_tensor = source_tensor.to(DEVICE)\n",
        "    source_mask = source_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(source_tensor, source_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len - 1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        target_mask = generate_square_subsequent_mask(ys.size(0))\n",
        "        target_mask = target_mask.type(torch.bool).to(DEVICE)\n",
        "\n",
        "        out = model.decode(memory, ys, target_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
        "        )\n",
        "\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def translate(model, source_sentence):\n",
        "    model.eval()\n",
        "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n",
        "    num_tokens = source_tensor.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
        "    ).flatten()\n",
        "\n",
        "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1]\n",
        "    return \" \".join(output)\n",
        "\n",
        "output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
        "output = translate(model, \"Eine Gruppe von Menschen steht vor einem Gebude .\")\n",
        "print(output_oov)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "452785ce",
      "metadata": {
        "id": "452785ce"
      },
      "source": [
        "# GPT-2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "45da021e237b40f8b5fea25ce412a201",
            "b27ced2b5dba4f18a436ade319f20362",
            "390a65c067254d47808dd2b470ab00f0"
          ]
        },
        "id": "SypBSHNZuySS",
        "outputId": "c76cb272-142f-4893-be7a-d6b7e2a7eb99"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45da021e237b40f8b5fea25ce412a201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b27ced2b5dba4f18a436ade319f20362",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "390a65c067254d47808dd2b470ab00f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformer\n",
            " wte\n",
            " wpe\n",
            " drop\n",
            " h\n",
            "    0\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    1\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    2\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    3\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    4\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    5\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    6\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    7\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    8\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    9\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    10\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            "    11\n",
            "       ln_1\n",
            "       attn\n",
            "       ln_2\n",
            "       mlp\n",
            " ln_f\n",
            "lm_head\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(pretrained_model_name_or_path=\"gpt2\")\n",
        "\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"   \", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"      \", sssub_name)\n"
      ],
      "id": "SypBSHNZuySS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a005e479",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4562657d2e084d9baa82823fdf58f491",
            "8499f2000cb646be8fb06251acd96ce4",
            "41ddc43de3fb47f4a336066dc3b9d158",
            "ea1f3dd864b74320b4689ce6487d8b03"
          ]
        },
        "id": "a005e479",
        "outputId": "ddee6dc2-80df-4638-a20e-fa923c085c6f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4562657d2e084d9baa82823fdf58f491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8499f2000cb646be8fb06251acd96ce4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41ddc43de3fb47f4a336066dc3b9d158",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea1f3dd864b74320b4689ce6487d8b03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Machine learning is becoming more complex for computer scientists and engineers. The new techniques are becoming increasingly important for analyzing, and improving, complex data sets. And while many of these techniques may not work in practice, they are becoming a major part of AI research.\\n\\nImage: Getty Images\\n\\nThis is probably too good to be true. But the fact that a few well-known algorithms, such as Turing\\'s, are being used to refine the process of classification of human knowledge in real time is one sign that the process is still evolving. This does not mean that machine learning is dead. But it has some new applications to give it more opportunities to be used in a variety of roles.\\n\\n\"What I\\'m seeing is that we are seeing a revolution in the way AI is used by the AI community,\" says Mark Dworkin, a postdoctoral researcher at Harvard University\\'s Artificial Intelligence Lab. \"You can see the future of computer science in this way.\"\\n\\nThe problem with AI is that it is often an imperfect tool for many tasks. It can be a tool for many different things. But for some tasks, it can be a tool for some different things.\\n\\n\"It is not clear how well it will work for what it does, and what it will'}, {'generated_text': 'Machine learning is the most commonly used technique in computer science to study human behavior. It encompasses the use of machine learning algorithms to identify patterns in data and to create a model of the behavior of individuals.\\n\\nThe techniques are often applied to a large variety of topics, from human-computer interactions to real-world scenarios. The primary method for computer scientists to identify patterns in data is called human-computer interaction, and is used in many industries, such as pharmaceuticals, telecommunications, and business.\\n\\nThe primary method for machine learning is called real-world situations. These situations are those in which individuals try to identify a pattern or predict future behavior (such as a new product or a business decision). Machine learning algorithms are used to predict such situations. For instance, a trained algorithm could identify patterns in a data set and predict that the data would be suitable for a particular type of analysis. In other words, if humans try to identify patterns in an object or a user, it will be able to predict that it will be a suitable target for new products or services.\\n\\nMachine learning algorithms are particularly useful for applications in complex situations. For instance, if you have a program that performs computations in the real world, and you want to learn about how the program works, computer'}, {'generated_text': \"Machine learning is a technique that enables you to predict many different outcomes, ranging from a successful lottery to a successful victory.\\n\\nThe problem is that, as we know, the world is not always the same. For example, in the United States, one in three Americans has at least one non-verbal and non-verbal behavior that has been shown to have a predictive value of about 2% or less. This means that most people can only predict what they see in their environment when they are doing a task well.\\n\\nIn the United States, some people can't identify with their environment until they are doing a task well, so when they are doing a task well, they have no way of knowing what they will see; in fact, they are so far only able to see what they see in the environment that they can't predict what they will see any other way.\\n\\nThere are many other social sciences and psychology that are based on non-verbal and non-verbal behaviors. In fact, you can learn about them from these disciplines through reading these books. I would like to share my research with you, but it is important to understand that most of the more complicated systems come down to how we evaluate and choose our life choices.\\n\\nThere are many different ways\"}]\n"
          ]
        }
      ],
      "source": [
        "# gpt-2    \n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
        "outputs = generator(\n",
        "    text_inputs=\"Machine learning is\",\n",
        "    max_length=20,\n",
        "    num_return_sequences=3,\n",
        "    pad_token_id=generator.tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcabaa95",
      "metadata": {
        "id": "fcabaa95",
        "outputId": "aa8d7dc5-e110-4617-febf-da220d951c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.1+cpu\n",
            "0.17.1+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "print(torch.__version__)\n",
        "print(torchtext.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f90a75",
      "metadata": {
        "id": "e5f90a75",
        "outputId": "5b4f8e2e-24dc-4f0e-9e83-f6495c295fda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset Length : 8550\n",
            "Valid Dataset Length : 526\n",
            "Test Dataset Length : 515\n"
          ]
        }
      ],
      "source": [
        "# CoLA  \n",
        "\n",
        "import torch\n",
        "from torchtext.datasets import CoLA\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collator(batch, tokenizer, device):\n",
        "    source, labels, texts = zip(*batch)\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
        "    return input_ids, attention_mask, labels\n",
        "\n",
        "train_data = list(CoLA(split=\"train\"))\n",
        "valid_data = list(CoLA(split=\"dev\"))\n",
        "test_data = list(CoLA(split=\"test\"))\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "epochs = 3\n",
        "batch_size = 16\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=lambda x: collator(x, tokenizer, device),\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_data,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=lambda x: collator(x, tokenizer, device),\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=lambda x: collator(x, tokenizer, device),\n",
        ")\n",
        "\n",
        "print(\"Train Dataset Length :\", len(train_data))\n",
        "print(\"Valid Dataset Length :\", len(valid_data))\n",
        "print(\"Test Dataset Length :\", len(test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1298f708",
      "metadata": {
        "id": "1298f708",
        "outputId": "ea7a7df6-ef00-4a68-aef9-7ea71706cf46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# gpt-2  \n",
        "\n",
        "from torch import optim\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"gpt2\",\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c40c8c3",
      "metadata": {
        "id": "7c40c8c3",
        "outputId": "a7daeb20-930e-413d-e8b3-4dfce9fea873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss: 0.4998 Val Loss: 0.5163 Val Accuracy: 0.7543\n",
            "Saved the model weights\n",
            "Epoch 2: Train Loss: 0.3611 Val Loss: 0.5219 Val Accuracy: 0.7562\n",
            "Epoch 3: Train Loss: 0.2552 Val Loss: 0.5331 Val Accuracy: 0.7652\n"
          ]
        }
      ],
      "source": [
        "# gpt-2    \n",
        "\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for input_ids, attention_mask, labels in dataloader:\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        val_loss, val_accuracy = 0.0, 0.0\n",
        "\n",
        "        for input_ids, attention_mask, labels in dataloader:\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to(\"cpu\").numpy()\n",
        "            accuracy = calc_accuracy(logits, label_ids)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_accuracy += accuracy\n",
        "\n",
        "        val_loss = val_loss / len(dataloader)\n",
        "        val_accuracy = val_accuracy / len(dataloader)\n",
        "\n",
        "        return val_loss, val_accuracy\n",
        "\n",
        "#  \n",
        "best_loss = 10000\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"GPT.pt\")\n",
        "        print(\"Saved the model weights\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ded6d49",
      "metadata": {
        "id": "3ded6d49"
      },
      "outputs": [],
      "source": [
        "#  \n",
        "\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "import torch\n",
        "\n",
        "#    \n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"gpt2\",\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "#   ID \n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "#   \n",
        "model.load_state_dict(torch.load(\"../models/GPT2ForSequenceClassification.pt\"))\n",
        "\n",
        "# \n",
        "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
        "\n",
        "print(f\"Test Loss : {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}